{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import collections\n",
    "import multiprocessing\n",
    "import yaml\n",
    "import gensim\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.core import Dense, Dropout,Activation\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Masking\n",
    "from keras.models import model_from_yaml\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "def loadsst(path):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    file1 = open(path, 'r')\n",
    "    Lines = file1.readlines()\n",
    "    for line in Lines:\n",
    "        soup = line.split()\n",
    "        ys.append(int(soup[0].lstrip('(')))\n",
    "        tokens = []\n",
    "        for chunk in soup[2:]:\n",
    "            if not chunk.endswith(\")\"):\n",
    "                continue\n",
    "            tokens.append(chunk.rstrip(')'))\n",
    "        xs.append(tokens)\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data successfully loaded\n"
     ]
    }
   ],
   "source": [
    "ssttrainxs, ssttrainys = loadsst(\"../comp0090/trainDevTestTrees_PTB/trees/train.txt\")\n",
    "sstvalidxs, sstvalidys = loadsst(\"../comp0090/trainDevTestTrees_PTB/trees/dev.txt\")\n",
    "ssttestxs, ssttestys = loadsst(\"../comp0090/trainDevTestTrees_PTB/trees/test.txt\")\n",
    "print(\"data successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary\n",
    "# Combine all data first because we need to use one dictionary\n",
    "total_x = np.concatenate((ssttrainxs,sstvalidxs,ssttestxs))\n",
    "\n",
    "VOCAB_SIZE = 5000\n",
    "counter = collections.Counter()\n",
    "maxlen = 0\n",
    "#count the maximum length of sentences in the set\n",
    "for i in range(total_x.shape[0]):\n",
    "    words = total_x[i]\n",
    "    if len(words) > maxlen:\n",
    "        maxlen = len(words)\n",
    "    for word in words:\n",
    "        counter[word] += 1\n",
    "\n",
    "#create the word2index model\n",
    "word2index = collections.defaultdict(int)\n",
    "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
    "    word2index[word[0]] = wid + 1\n",
    "vocab_sz = len(word2index) + 1\n",
    "index2word = {v: k for k, v in word2index.items()}\n",
    "\n",
    "#apply the word2index model to the set and get the fixed-length onehot format set\n",
    "xs, ys = [], []\n",
    "for i in range(total_x.shape[0]):\n",
    "    words = total_x[i]\n",
    "    wids = [word2index[word] for word in words]\n",
    "    xs.append(wids)\n",
    "X = pad_sequences(xs, maxlen=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD2VEC_MODEL = '../comp0090/GoogleNews-vectors-negative300.bin.gz'\n",
    "EMBED_SIZE = 300\n",
    "word2vec = KeyedVectors.load_word2vec_format(WORD2VEC_MODEL, binary = True)\n",
    "\n",
    "# embedding function\n",
    "def embedding(token):\n",
    "# If a token is not in our vocabulary, we use UNK to represent it.\n",
    "    if token in word2vec.vocab:\n",
    "        token = token\n",
    "    else:\n",
    "        token = \"UNK\"\n",
    "    return word2vec[token]\n",
    "\n",
    "# Define embedding weights\n",
    "embedding_weights = np.zeros((vocab_sz, EMBED_SIZE))\n",
    "for word, index in word2index.items():\n",
    "    embedding_weights[index, :] = embedding(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the train set, validation set and test set\n",
    "train_siz = 8544\n",
    "val_siz = 1101\n",
    "test_siz = 2201\n",
    "train_x = X[:train_siz,:]\n",
    "valid_x = X[train_siz:train_siz+val_siz,:]\n",
    "test_x = X[train_siz+val_siz:,:]\n",
    "\n",
    "# process labels dataset\n",
    "train_y = keras.utils.to_categorical(ssttrainys,num_classes=5)\n",
    "valid_y = keras.utils.to_categorical(sstvalidys,num_classes=5)\n",
    "test_y = keras.utils.to_categorical(ssttestys,num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE all parameters here for tuning\n",
    "pool_flag = 'max'\n",
    "embedding_fix = False\n",
    "layer_sizes = [128, 80, 20]\n",
    "\n",
    "vocab_dim = 300\n",
    "input_length = 56\n",
    "n_epoch = 30\n",
    "batch_size = 128\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process\n",
    "cpu_count = multiprocessing.cpu_count() # 4\n",
    "\n",
    "# define the early_stopping function\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "#define the model\n",
    "model = Sequential()\n",
    "# add the embedding\n",
    "model.add(Embedding(output_dim = vocab_dim,\n",
    "                    input_dim = VOCAB_SIZE + 1,\n",
    "                    mask_zero = True,\n",
    "                    weights = [embedding_weights],\n",
    "                    input_length = input_length,\n",
    "                    trainable = not(embedding_fix)))\n",
    "#add pooling layer\n",
    "model.add(Masking(mask_value = 0.0))\n",
    "if pool_flag == 'mean':\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "else:\n",
    "    model.add(GlobalMaxPooling1D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 1.5741 - accuracy: 0.2688 - val_loss: 1.5679 - val_accuracy: 0.2525\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.5566 - accuracy: 0.2882 - val_loss: 1.5563 - val_accuracy: 0.2897\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.5437 - accuracy: 0.3166 - val_loss: 1.5436 - val_accuracy: 0.3297\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 1.5298 - accuracy: 0.3392 - val_loss: 1.5315 - val_accuracy: 0.3361\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 1.5113 - accuracy: 0.3580 - val_loss: 1.5122 - val_accuracy: 0.3488\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 1.4853 - accuracy: 0.3666 - val_loss: 1.4838 - val_accuracy: 0.3515\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.4468 - accuracy: 0.3791 - val_loss: 1.4594 - val_accuracy: 0.3524\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 1.4024 - accuracy: 0.3943 - val_loss: 1.4318 - val_accuracy: 0.3769\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 1.3584 - accuracy: 0.4103 - val_loss: 1.3916 - val_accuracy: 0.3724\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.3121 - accuracy: 0.4339 - val_loss: 1.3698 - val_accuracy: 0.3797\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 1.2721 - accuracy: 0.4496 - val_loss: 1.3487 - val_accuracy: 0.3869\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 1.2292 - accuracy: 0.4751 - val_loss: 1.3423 - val_accuracy: 0.3815\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 1.1897 - accuracy: 0.4898 - val_loss: 1.3292 - val_accuracy: 0.3869\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.1534 - accuracy: 0.5089 - val_loss: 1.3264 - val_accuracy: 0.3924\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 1.1169 - accuracy: 0.5266 - val_loss: 1.3189 - val_accuracy: 0.3942\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 1.0863 - accuracy: 0.5382 - val_loss: 1.3240 - val_accuracy: 0.3987\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 1.0509 - accuracy: 0.5556 - val_loss: 1.3263 - val_accuracy: 0.4015\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 1.0174 - accuracy: 0.5729 - val_loss: 1.3305 - val_accuracy: 0.3942\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 3s 38ms/step - loss: 0.9860 - accuracy: 0.5913 - val_loss: 1.3377 - val_accuracy: 0.4042\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.9584 - accuracy: 0.6052 - val_loss: 1.3442 - val_accuracy: 0.4114\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 2s 35ms/step - loss: 0.9241 - accuracy: 0.6232 - val_loss: 1.3586 - val_accuracy: 0.4105\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 0.8936 - accuracy: 0.6424 - val_loss: 1.3857 - val_accuracy: 0.4033\n",
      "Epoch 23/30\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 0.8667 - accuracy: 0.6505 - val_loss: 1.3836 - val_accuracy: 0.4096\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 0.8344 - accuracy: 0.6747 - val_loss: 1.4042 - val_accuracy: 0.4015\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 0.8043 - accuracy: 0.6890 - val_loss: 1.4300 - val_accuracy: 0.4042\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.7783 - accuracy: 0.7058 - val_loss: 1.4465 - val_accuracy: 0.4114\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.7463 - accuracy: 0.7204 - val_loss: 1.4714 - val_accuracy: 0.4114\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.7191 - accuracy: 0.7341 - val_loss: 1.5047 - val_accuracy: 0.4096\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 0.6921 - accuracy: 0.7511 - val_loss: 1.5117 - val_accuracy: 0.4105\n",
      "Epoch 30/30\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 0.6630 - accuracy: 0.7649 - val_loss: 1.5451 - val_accuracy: 0.4060\n",
      "Train set\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.7775\n",
      "Validation set\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.5451 - accuracy: 0.4060\n",
      "Test set\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.5322 - accuracy: 0.4072\n"
     ]
    }
   ],
   "source": [
    "#add layers of MLP\n",
    "for i in layer_sizes:\n",
    "    model.add(Dense(units = i, activation = 'relu'))\n",
    "model.add(Dense(units = 5, activation = 'softmax'))\n",
    "\n",
    "#using cross entropy loss and Adam optimizer\n",
    "adam = keras.optimizers.Adam(lr = lr, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "#use fit function to do gradient descent, save the accuracy and loss of each epoch in history\n",
    "history = model.fit(train_x, train_y, batch_size = batch_size, epochs = n_epoch, verbose = 1, validation_data = (valid_x, valid_y))\n",
    "\n",
    "print (\"Train set\")\n",
    "score = model.evaluate(train_x, train_y,batch_size = batch_size)\n",
    "print (\"Validation set\")\n",
    "score = model.evaluate(valid_x, valid_y,batch_size = batch_size)\n",
    "print (\"Test set\")\n",
    "score = model.evaluate(test_x, test_y,batch_size = batch_size)\n",
    "\n",
    "#use yaml to save the model and weights on the drive for prediction later\n",
    "yaml_string = model.to_yaml()\n",
    "with open('../comp0090/mlp.yml', 'w') as outfile:\n",
    "    outfile.write( yaml.dump(yaml_string, default_flow_style=True) )\n",
    "model.save_weights('../comp0090/mlp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 1.5827 - accuracy: 0.2676 - val_loss: 1.5750 - val_accuracy: 0.2534\n",
      "Epoch 2/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.5691 - accuracy: 0.2776 - val_loss: 1.5719 - val_accuracy: 0.2534\n",
      "Epoch 3/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.5662 - accuracy: 0.2800 - val_loss: 1.5691 - val_accuracy: 0.2534\n",
      "Epoch 4/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.5642 - accuracy: 0.2925 - val_loss: 1.5661 - val_accuracy: 0.2543\n",
      "Epoch 5/500\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 1.5598 - accuracy: 0.2980 - val_loss: 1.5611 - val_accuracy: 0.3061\n",
      "Epoch 6/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.5560 - accuracy: 0.3103 - val_loss: 1.5570 - val_accuracy: 0.3143\n",
      "Epoch 7/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.5501 - accuracy: 0.3242 - val_loss: 1.5513 - val_accuracy: 0.2788\n",
      "Epoch 8/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.5431 - accuracy: 0.3407 - val_loss: 1.5424 - val_accuracy: 0.2943\n",
      "Epoch 9/500\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 1.5335 - accuracy: 0.3425 - val_loss: 1.5353 - val_accuracy: 0.2925\n",
      "Epoch 10/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.5216 - accuracy: 0.3510 - val_loss: 1.5216 - val_accuracy: 0.3152\n",
      "Epoch 11/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.5062 - accuracy: 0.3591 - val_loss: 1.5042 - val_accuracy: 0.3624\n",
      "Epoch 12/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.4901 - accuracy: 0.3641 - val_loss: 1.5102 - val_accuracy: 0.3052\n",
      "Epoch 13/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.4731 - accuracy: 0.3703 - val_loss: 1.4726 - val_accuracy: 0.3624\n",
      "Epoch 14/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 1.4537 - accuracy: 0.3766 - val_loss: 1.4694 - val_accuracy: 0.3560\n",
      "Epoch 15/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.4381 - accuracy: 0.3832 - val_loss: 1.4439 - val_accuracy: 0.3651\n",
      "Epoch 16/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.4214 - accuracy: 0.3906 - val_loss: 1.4278 - val_accuracy: 0.3815\n",
      "Epoch 17/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.4046 - accuracy: 0.3951 - val_loss: 1.4615 - val_accuracy: 0.3515\n",
      "Epoch 18/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.3900 - accuracy: 0.4017 - val_loss: 1.4218 - val_accuracy: 0.3697\n",
      "Epoch 19/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.3732 - accuracy: 0.4132 - val_loss: 1.3968 - val_accuracy: 0.3951\n",
      "Epoch 20/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.3594 - accuracy: 0.4144 - val_loss: 1.3904 - val_accuracy: 0.3860\n",
      "Epoch 21/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.3468 - accuracy: 0.4188 - val_loss: 1.3820 - val_accuracy: 0.3960\n",
      "Epoch 22/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 1.3313 - accuracy: 0.4283 - val_loss: 1.4051 - val_accuracy: 0.3833\n",
      "Epoch 23/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 1.3182 - accuracy: 0.4313 - val_loss: 1.3978 - val_accuracy: 0.3724\n",
      "Epoch 24/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.3059 - accuracy: 0.4397 - val_loss: 1.3618 - val_accuracy: 0.4060\n",
      "Epoch 25/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 1.2957 - accuracy: 0.4380 - val_loss: 1.4200 - val_accuracy: 0.3678\n",
      "Epoch 26/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.2853 - accuracy: 0.4456 - val_loss: 1.3662 - val_accuracy: 0.3860\n",
      "Epoch 27/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 1.2725 - accuracy: 0.4459 - val_loss: 1.3738 - val_accuracy: 0.4024\n",
      "Epoch 28/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.2646 - accuracy: 0.4512 - val_loss: 1.3488 - val_accuracy: 0.3996\n",
      "Epoch 29/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 1.2564 - accuracy: 0.4537 - val_loss: 1.4064 - val_accuracy: 0.3769\n",
      "Epoch 30/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.2434 - accuracy: 0.4582 - val_loss: 1.3681 - val_accuracy: 0.4024\n",
      "Epoch 31/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.2388 - accuracy: 0.4607 - val_loss: 1.3442 - val_accuracy: 0.3933\n",
      "Epoch 32/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.2286 - accuracy: 0.4654 - val_loss: 1.3609 - val_accuracy: 0.4051\n",
      "Epoch 33/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.2238 - accuracy: 0.4662 - val_loss: 1.3441 - val_accuracy: 0.4015\n",
      "Epoch 34/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.2152 - accuracy: 0.4697 - val_loss: 1.3451 - val_accuracy: 0.4005\n",
      "Epoch 35/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.2039 - accuracy: 0.4696 - val_loss: 1.4047 - val_accuracy: 0.3924\n",
      "Epoch 36/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.1976 - accuracy: 0.4727 - val_loss: 1.3463 - val_accuracy: 0.4078\n",
      "Epoch 37/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.1913 - accuracy: 0.4733 - val_loss: 1.3491 - val_accuracy: 0.4024\n",
      "Epoch 38/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.1866 - accuracy: 0.4790 - val_loss: 1.3649 - val_accuracy: 0.3996\n",
      "Epoch 39/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.1818 - accuracy: 0.4773 - val_loss: 1.3476 - val_accuracy: 0.4060\n",
      "Epoch 40/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.1747 - accuracy: 0.4876 - val_loss: 1.3595 - val_accuracy: 0.3960\n",
      "Epoch 41/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.1697 - accuracy: 0.4858 - val_loss: 1.4359 - val_accuracy: 0.3887\n",
      "Epoch 42/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.1649 - accuracy: 0.4881 - val_loss: 1.4062 - val_accuracy: 0.3978\n",
      "Epoch 43/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.1577 - accuracy: 0.4898 - val_loss: 1.4091 - val_accuracy: 0.3942\n",
      "Epoch 44/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.1541 - accuracy: 0.4925 - val_loss: 1.3953 - val_accuracy: 0.3933\n",
      "Epoch 45/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.1502 - accuracy: 0.4939 - val_loss: 1.3779 - val_accuracy: 0.4042\n",
      "Epoch 46/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.1405 - accuracy: 0.4970 - val_loss: 1.3938 - val_accuracy: 0.4033\n",
      "Epoch 47/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 1.1350 - accuracy: 0.4986 - val_loss: 1.3762 - val_accuracy: 0.4142\n",
      "Epoch 48/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.1368 - accuracy: 0.5004 - val_loss: 1.3799 - val_accuracy: 0.4060\n",
      "Epoch 49/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.1239 - accuracy: 0.5012 - val_loss: 1.4062 - val_accuracy: 0.4024\n",
      "Epoch 50/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.1252 - accuracy: 0.5037 - val_loss: 1.3892 - val_accuracy: 0.3978\n",
      "Epoch 51/500\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 1.1168 - accuracy: 0.5090 - val_loss: 1.3742 - val_accuracy: 0.4114\n",
      "Epoch 52/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.1131 - accuracy: 0.5116 - val_loss: 1.4240 - val_accuracy: 0.3969\n",
      "Epoch 53/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.1098 - accuracy: 0.5217 - val_loss: 1.4059 - val_accuracy: 0.3860\n",
      "Epoch 54/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.0996 - accuracy: 0.5222 - val_loss: 1.4037 - val_accuracy: 0.4033\n",
      "Epoch 55/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.1047 - accuracy: 0.5205 - val_loss: 1.4355 - val_accuracy: 0.4042\n",
      "Epoch 56/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.0946 - accuracy: 0.5213 - val_loss: 1.4414 - val_accuracy: 0.4033\n",
      "Epoch 57/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.0918 - accuracy: 0.5210 - val_loss: 1.3961 - val_accuracy: 0.4096\n",
      "Epoch 58/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.0899 - accuracy: 0.5200 - val_loss: 1.5035 - val_accuracy: 0.3869\n",
      "Epoch 59/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.0888 - accuracy: 0.5256 - val_loss: 1.4121 - val_accuracy: 0.3924\n",
      "Epoch 60/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.0811 - accuracy: 0.5300 - val_loss: 1.4718 - val_accuracy: 0.3960\n",
      "Epoch 61/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.0784 - accuracy: 0.5267 - val_loss: 1.4335 - val_accuracy: 0.3778\n",
      "Epoch 62/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.0787 - accuracy: 0.5288 - val_loss: 1.4384 - val_accuracy: 0.3996\n",
      "Epoch 63/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.0705 - accuracy: 0.5389 - val_loss: 1.4157 - val_accuracy: 0.4078\n",
      "Epoch 64/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.0683 - accuracy: 0.5369 - val_loss: 1.4620 - val_accuracy: 0.3769\n",
      "Epoch 65/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.0648 - accuracy: 0.5370 - val_loss: 1.5000 - val_accuracy: 0.3851\n",
      "Epoch 66/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.0601 - accuracy: 0.5421 - val_loss: 1.4608 - val_accuracy: 0.4005\n",
      "Epoch 67/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.0590 - accuracy: 0.5371 - val_loss: 1.5153 - val_accuracy: 0.3860\n",
      "Epoch 68/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.0592 - accuracy: 0.5420 - val_loss: 1.4530 - val_accuracy: 0.4033\n",
      "Epoch 69/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.0523 - accuracy: 0.5448 - val_loss: 1.4515 - val_accuracy: 0.3996\n",
      "Epoch 70/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 1.0493 - accuracy: 0.5447 - val_loss: 1.4586 - val_accuracy: 0.4042\n",
      "Epoch 71/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 1.0450 - accuracy: 0.5451 - val_loss: 1.4797 - val_accuracy: 0.3969\n",
      "Epoch 72/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.0450 - accuracy: 0.5448 - val_loss: 1.4943 - val_accuracy: 0.3978\n",
      "Epoch 73/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.0405 - accuracy: 0.5536 - val_loss: 1.4543 - val_accuracy: 0.3887\n",
      "Epoch 74/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.0396 - accuracy: 0.5581 - val_loss: 1.4559 - val_accuracy: 0.3887\n",
      "Epoch 75/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.0343 - accuracy: 0.5596 - val_loss: 1.4737 - val_accuracy: 0.4024\n",
      "Epoch 76/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.0318 - accuracy: 0.5603 - val_loss: 1.4637 - val_accuracy: 0.3960\n",
      "Epoch 77/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.0323 - accuracy: 0.5602 - val_loss: 1.5227 - val_accuracy: 0.3751\n",
      "Epoch 78/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.0284 - accuracy: 0.5657 - val_loss: 1.4733 - val_accuracy: 0.3806\n",
      "Epoch 79/500\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 1.0220 - accuracy: 0.5636 - val_loss: 1.4776 - val_accuracy: 0.3924\n",
      "Epoch 80/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 1.0225 - accuracy: 0.5633 - val_loss: 1.4832 - val_accuracy: 0.4024\n",
      "Epoch 81/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.0140 - accuracy: 0.5721 - val_loss: 1.4978 - val_accuracy: 0.3724\n",
      "Epoch 82/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 1.0119 - accuracy: 0.5689 - val_loss: 1.5089 - val_accuracy: 0.4015\n",
      "Epoch 83/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 1.0125 - accuracy: 0.5714 - val_loss: 1.4878 - val_accuracy: 0.3969\n",
      "Epoch 84/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.0080 - accuracy: 0.5727 - val_loss: 1.5104 - val_accuracy: 0.3960\n",
      "Epoch 85/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 1.0057 - accuracy: 0.5770 - val_loss: 1.5005 - val_accuracy: 0.3860\n",
      "Epoch 86/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 1.0022 - accuracy: 0.5832 - val_loss: 1.5470 - val_accuracy: 0.3688\n",
      "Epoch 87/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 1.0031 - accuracy: 0.5792 - val_loss: 1.5060 - val_accuracy: 0.3960\n",
      "Epoch 88/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.9994 - accuracy: 0.5801 - val_loss: 1.5802 - val_accuracy: 0.3842\n",
      "Epoch 89/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9922 - accuracy: 0.5853 - val_loss: 1.5402 - val_accuracy: 0.3987\n",
      "Epoch 90/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9929 - accuracy: 0.5823 - val_loss: 1.5278 - val_accuracy: 0.3760\n",
      "Epoch 91/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.9900 - accuracy: 0.5886 - val_loss: 1.5236 - val_accuracy: 0.3896\n",
      "Epoch 92/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.9894 - accuracy: 0.5868 - val_loss: 1.5929 - val_accuracy: 0.3869\n",
      "Epoch 93/500\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.9820 - accuracy: 0.5925 - val_loss: 1.5306 - val_accuracy: 0.3924\n",
      "Epoch 94/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.9809 - accuracy: 0.5886 - val_loss: 1.5565 - val_accuracy: 0.3987\n",
      "Epoch 95/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.9786 - accuracy: 0.5939 - val_loss: 1.5388 - val_accuracy: 0.3869\n",
      "Epoch 96/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.9785 - accuracy: 0.5928 - val_loss: 1.5662 - val_accuracy: 0.3697\n",
      "Epoch 97/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.9725 - accuracy: 0.5994 - val_loss: 1.5464 - val_accuracy: 0.3869\n",
      "Epoch 98/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9716 - accuracy: 0.5968 - val_loss: 1.5571 - val_accuracy: 0.3896\n",
      "Epoch 99/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.9672 - accuracy: 0.5980 - val_loss: 1.6387 - val_accuracy: 0.3860\n",
      "Epoch 100/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.9603 - accuracy: 0.6046 - val_loss: 1.5623 - val_accuracy: 0.3924\n",
      "Epoch 101/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.9659 - accuracy: 0.5963 - val_loss: 1.5631 - val_accuracy: 0.3869\n",
      "Epoch 102/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9588 - accuracy: 0.6064 - val_loss: 1.5868 - val_accuracy: 0.4015\n",
      "Epoch 103/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9585 - accuracy: 0.6072 - val_loss: 1.5805 - val_accuracy: 0.3715\n",
      "Epoch 104/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9485 - accuracy: 0.6087 - val_loss: 1.5714 - val_accuracy: 0.3860\n",
      "Epoch 105/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9554 - accuracy: 0.6035 - val_loss: 1.6181 - val_accuracy: 0.3933\n",
      "Epoch 106/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9500 - accuracy: 0.6114 - val_loss: 1.5825 - val_accuracy: 0.3860\n",
      "Epoch 107/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9446 - accuracy: 0.6126 - val_loss: 1.5982 - val_accuracy: 0.3815\n",
      "Epoch 108/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.9477 - accuracy: 0.6141 - val_loss: 1.6569 - val_accuracy: 0.3896\n",
      "Epoch 109/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.9432 - accuracy: 0.6143 - val_loss: 1.6063 - val_accuracy: 0.3915\n",
      "Epoch 110/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9401 - accuracy: 0.6161 - val_loss: 1.6503 - val_accuracy: 0.3915\n",
      "Epoch 111/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9347 - accuracy: 0.6196 - val_loss: 1.6448 - val_accuracy: 0.3969\n",
      "Epoch 112/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9333 - accuracy: 0.6209 - val_loss: 1.6125 - val_accuracy: 0.3878\n",
      "Epoch 113/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9261 - accuracy: 0.6255 - val_loss: 1.6435 - val_accuracy: 0.3878\n",
      "Epoch 114/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.9285 - accuracy: 0.6190 - val_loss: 1.6129 - val_accuracy: 0.3842\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9300 - accuracy: 0.6208 - val_loss: 1.6579 - val_accuracy: 0.3960\n",
      "Epoch 116/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9183 - accuracy: 0.6239 - val_loss: 1.6606 - val_accuracy: 0.3833\n",
      "Epoch 117/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.9186 - accuracy: 0.6217 - val_loss: 1.6854 - val_accuracy: 0.3887\n",
      "Epoch 118/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.9152 - accuracy: 0.6257 - val_loss: 1.6573 - val_accuracy: 0.3933\n",
      "Epoch 119/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.9138 - accuracy: 0.6286 - val_loss: 1.6424 - val_accuracy: 0.3924\n",
      "Epoch 120/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.9091 - accuracy: 0.6344 - val_loss: 1.7168 - val_accuracy: 0.3878\n",
      "Epoch 121/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.9156 - accuracy: 0.6271 - val_loss: 1.6583 - val_accuracy: 0.3906\n",
      "Epoch 122/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9040 - accuracy: 0.6355 - val_loss: 1.6496 - val_accuracy: 0.3833\n",
      "Epoch 123/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.9050 - accuracy: 0.6347 - val_loss: 1.7112 - val_accuracy: 0.3942\n",
      "Epoch 124/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8972 - accuracy: 0.6441 - val_loss: 1.6654 - val_accuracy: 0.3887\n",
      "Epoch 125/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8970 - accuracy: 0.6372 - val_loss: 1.7428 - val_accuracy: 0.3579\n",
      "Epoch 126/500\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.8922 - accuracy: 0.6430 - val_loss: 1.7724 - val_accuracy: 0.3769\n",
      "Epoch 127/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.9008 - accuracy: 0.6346 - val_loss: 1.6764 - val_accuracy: 0.3933\n",
      "Epoch 128/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8908 - accuracy: 0.6412 - val_loss: 1.6824 - val_accuracy: 0.3915\n",
      "Epoch 129/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8839 - accuracy: 0.6417 - val_loss: 1.6884 - val_accuracy: 0.3778\n",
      "Epoch 130/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8848 - accuracy: 0.6409 - val_loss: 1.7211 - val_accuracy: 0.3869\n",
      "Epoch 131/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8795 - accuracy: 0.6471 - val_loss: 1.6973 - val_accuracy: 0.3724\n",
      "Epoch 132/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8800 - accuracy: 0.6427 - val_loss: 1.7542 - val_accuracy: 0.3851\n",
      "Epoch 133/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8751 - accuracy: 0.6457 - val_loss: 1.6988 - val_accuracy: 0.3815\n",
      "Epoch 134/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8756 - accuracy: 0.6506 - val_loss: 1.7394 - val_accuracy: 0.3933\n",
      "Epoch 135/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8680 - accuracy: 0.6506 - val_loss: 1.7399 - val_accuracy: 0.3869\n",
      "Epoch 136/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8682 - accuracy: 0.6513 - val_loss: 1.7240 - val_accuracy: 0.3769\n",
      "Epoch 137/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8616 - accuracy: 0.6550 - val_loss: 1.7265 - val_accuracy: 0.3860\n",
      "Epoch 138/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8636 - accuracy: 0.6561 - val_loss: 1.7439 - val_accuracy: 0.3978\n",
      "Epoch 139/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8614 - accuracy: 0.6571 - val_loss: 1.7423 - val_accuracy: 0.3833\n",
      "Epoch 140/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8558 - accuracy: 0.6596 - val_loss: 1.8214 - val_accuracy: 0.3887\n",
      "Epoch 141/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8536 - accuracy: 0.6571 - val_loss: 1.7604 - val_accuracy: 0.3778\n",
      "Epoch 142/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8529 - accuracy: 0.6613 - val_loss: 2.0977 - val_accuracy: 0.3488\n",
      "Epoch 143/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8578 - accuracy: 0.6553 - val_loss: 1.8133 - val_accuracy: 0.3742\n",
      "Epoch 144/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8453 - accuracy: 0.6640 - val_loss: 1.7664 - val_accuracy: 0.3860\n",
      "Epoch 145/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8395 - accuracy: 0.6680 - val_loss: 1.7768 - val_accuracy: 0.3896\n",
      "Epoch 146/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8397 - accuracy: 0.6676 - val_loss: 1.7800 - val_accuracy: 0.3778\n",
      "Epoch 147/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8361 - accuracy: 0.6692 - val_loss: 1.8324 - val_accuracy: 0.3678\n",
      "Epoch 148/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.8425 - accuracy: 0.6667 - val_loss: 1.7993 - val_accuracy: 0.3933\n",
      "Epoch 149/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.8308 - accuracy: 0.6703 - val_loss: 1.7860 - val_accuracy: 0.3787\n",
      "Epoch 150/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.8305 - accuracy: 0.6730 - val_loss: 1.7993 - val_accuracy: 0.3797\n",
      "Epoch 151/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8289 - accuracy: 0.6728 - val_loss: 1.8185 - val_accuracy: 0.3815\n",
      "Epoch 152/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.8239 - accuracy: 0.6765 - val_loss: 1.8057 - val_accuracy: 0.3797\n",
      "Epoch 153/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8209 - accuracy: 0.6774 - val_loss: 1.8553 - val_accuracy: 0.3742\n",
      "Epoch 154/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8237 - accuracy: 0.6768 - val_loss: 1.8221 - val_accuracy: 0.3715\n",
      "Epoch 155/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8199 - accuracy: 0.6778 - val_loss: 1.8371 - val_accuracy: 0.3915\n",
      "Epoch 156/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.8132 - accuracy: 0.6863 - val_loss: 1.8652 - val_accuracy: 0.3733\n",
      "Epoch 157/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8157 - accuracy: 0.6779 - val_loss: 1.8391 - val_accuracy: 0.3833\n",
      "Epoch 158/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8131 - accuracy: 0.6828 - val_loss: 1.9600 - val_accuracy: 0.3751\n",
      "Epoch 159/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8051 - accuracy: 0.6857 - val_loss: 1.8586 - val_accuracy: 0.3869\n",
      "Epoch 160/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8039 - accuracy: 0.6887 - val_loss: 1.9485 - val_accuracy: 0.3778\n",
      "Epoch 161/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.8011 - accuracy: 0.6888 - val_loss: 1.8655 - val_accuracy: 0.3842\n",
      "Epoch 162/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8044 - accuracy: 0.6829 - val_loss: 1.8784 - val_accuracy: 0.3951\n",
      "Epoch 163/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7967 - accuracy: 0.6916 - val_loss: 1.8971 - val_accuracy: 0.3942\n",
      "Epoch 164/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.8003 - accuracy: 0.6883 - val_loss: 1.8859 - val_accuracy: 0.3733\n",
      "Epoch 165/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7932 - accuracy: 0.6971 - val_loss: 1.8946 - val_accuracy: 0.3924\n",
      "Epoch 166/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7868 - accuracy: 0.6969 - val_loss: 1.9905 - val_accuracy: 0.3787\n",
      "Epoch 167/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7914 - accuracy: 0.6953 - val_loss: 1.8836 - val_accuracy: 0.3715\n",
      "Epoch 168/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7866 - accuracy: 0.6944 - val_loss: 1.8860 - val_accuracy: 0.3724\n",
      "Epoch 169/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7838 - accuracy: 0.6962 - val_loss: 1.8944 - val_accuracy: 0.3751\n",
      "Epoch 170/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7794 - accuracy: 0.6955 - val_loss: 1.9066 - val_accuracy: 0.3860\n",
      "Epoch 171/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7821 - accuracy: 0.6956 - val_loss: 1.9135 - val_accuracy: 0.3724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7727 - accuracy: 0.7015 - val_loss: 1.9564 - val_accuracy: 0.3896\n",
      "Epoch 173/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7771 - accuracy: 0.7019 - val_loss: 1.9594 - val_accuracy: 0.3869\n",
      "Epoch 174/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7713 - accuracy: 0.7040 - val_loss: 1.9584 - val_accuracy: 0.3960\n",
      "Epoch 175/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7651 - accuracy: 0.7056 - val_loss: 1.9294 - val_accuracy: 0.3851\n",
      "Epoch 176/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7638 - accuracy: 0.7070 - val_loss: 1.9388 - val_accuracy: 0.3778\n",
      "Epoch 177/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7641 - accuracy: 0.6987 - val_loss: 1.9539 - val_accuracy: 0.3851\n",
      "Epoch 178/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.7647 - accuracy: 0.7100 - val_loss: 1.9792 - val_accuracy: 0.3787\n",
      "Epoch 179/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7584 - accuracy: 0.7115 - val_loss: 2.0387 - val_accuracy: 0.3860\n",
      "Epoch 180/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.7605 - accuracy: 0.7068 - val_loss: 1.9661 - val_accuracy: 0.3751\n",
      "Epoch 181/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7527 - accuracy: 0.7120 - val_loss: 1.9588 - val_accuracy: 0.3769\n",
      "Epoch 182/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7561 - accuracy: 0.7151 - val_loss: 1.9746 - val_accuracy: 0.3751\n",
      "Epoch 183/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7497 - accuracy: 0.7142 - val_loss: 2.1329 - val_accuracy: 0.3769\n",
      "Epoch 184/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7522 - accuracy: 0.7152 - val_loss: 1.9804 - val_accuracy: 0.3742\n",
      "Epoch 185/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7489 - accuracy: 0.7118 - val_loss: 2.0390 - val_accuracy: 0.3669\n",
      "Epoch 186/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7421 - accuracy: 0.7118 - val_loss: 2.1260 - val_accuracy: 0.3806\n",
      "Epoch 187/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7471 - accuracy: 0.7162 - val_loss: 2.0069 - val_accuracy: 0.3688\n",
      "Epoch 188/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7367 - accuracy: 0.7189 - val_loss: 2.0672 - val_accuracy: 0.3606\n",
      "Epoch 189/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7360 - accuracy: 0.7237 - val_loss: 2.0058 - val_accuracy: 0.3797\n",
      "Epoch 190/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7380 - accuracy: 0.7197 - val_loss: 2.0464 - val_accuracy: 0.3678\n",
      "Epoch 191/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7350 - accuracy: 0.7199 - val_loss: 2.0298 - val_accuracy: 0.3833\n",
      "Epoch 192/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7260 - accuracy: 0.7262 - val_loss: 2.0617 - val_accuracy: 0.3678\n",
      "Epoch 193/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7301 - accuracy: 0.7212 - val_loss: 2.0402 - val_accuracy: 0.3787\n",
      "Epoch 194/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7248 - accuracy: 0.7241 - val_loss: 2.0588 - val_accuracy: 0.3769\n",
      "Epoch 195/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7232 - accuracy: 0.7253 - val_loss: 2.0948 - val_accuracy: 0.3651\n",
      "Epoch 196/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7223 - accuracy: 0.7301 - val_loss: 2.0707 - val_accuracy: 0.3896\n",
      "Epoch 197/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7225 - accuracy: 0.7285 - val_loss: 2.0764 - val_accuracy: 0.3797\n",
      "Epoch 198/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7158 - accuracy: 0.7341 - val_loss: 2.1261 - val_accuracy: 0.3878\n",
      "Epoch 199/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.7134 - accuracy: 0.7310 - val_loss: 2.1385 - val_accuracy: 0.3706\n",
      "Epoch 200/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7148 - accuracy: 0.7276 - val_loss: 2.0933 - val_accuracy: 0.3797\n",
      "Epoch 201/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7082 - accuracy: 0.7322 - val_loss: 2.1512 - val_accuracy: 0.3533\n",
      "Epoch 202/500\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.7089 - accuracy: 0.7331 - val_loss: 2.1098 - val_accuracy: 0.3769\n",
      "Epoch 203/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.7028 - accuracy: 0.7384 - val_loss: 2.1754 - val_accuracy: 0.3787\n",
      "Epoch 204/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.7036 - accuracy: 0.7331 - val_loss: 2.1209 - val_accuracy: 0.3778\n",
      "Epoch 205/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 0.7052 - accuracy: 0.7365 - val_loss: 2.1201 - val_accuracy: 0.3733\n",
      "Epoch 206/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.7001 - accuracy: 0.7408 - val_loss: 2.1367 - val_accuracy: 0.3869\n",
      "Epoch 207/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.6951 - accuracy: 0.7417 - val_loss: 2.1248 - val_accuracy: 0.3806\n",
      "Epoch 208/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6950 - accuracy: 0.7410 - val_loss: 2.1720 - val_accuracy: 0.3815\n",
      "Epoch 209/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6911 - accuracy: 0.7424 - val_loss: 2.2140 - val_accuracy: 0.3815\n",
      "Epoch 210/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6890 - accuracy: 0.7434 - val_loss: 2.1783 - val_accuracy: 0.3896\n",
      "Epoch 211/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6855 - accuracy: 0.7420 - val_loss: 2.1570 - val_accuracy: 0.3824\n",
      "Epoch 212/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6820 - accuracy: 0.7453 - val_loss: 2.1670 - val_accuracy: 0.3887\n",
      "Epoch 213/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6824 - accuracy: 0.7434 - val_loss: 2.1711 - val_accuracy: 0.3842\n",
      "Epoch 214/500\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.6842 - accuracy: 0.7489 - val_loss: 2.1805 - val_accuracy: 0.3824\n",
      "Epoch 215/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6806 - accuracy: 0.7444 - val_loss: 2.2282 - val_accuracy: 0.3724\n",
      "Epoch 216/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.6785 - accuracy: 0.7458 - val_loss: 2.2523 - val_accuracy: 0.3733\n",
      "Epoch 217/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.6819 - accuracy: 0.7470 - val_loss: 2.2796 - val_accuracy: 0.3488\n",
      "Epoch 218/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6724 - accuracy: 0.7508 - val_loss: 2.2301 - val_accuracy: 0.3706\n",
      "Epoch 219/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6722 - accuracy: 0.7479 - val_loss: 2.2006 - val_accuracy: 0.3797\n",
      "Epoch 220/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.6678 - accuracy: 0.7520 - val_loss: 2.2594 - val_accuracy: 0.3797\n",
      "Epoch 221/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6670 - accuracy: 0.7566 - val_loss: 2.2871 - val_accuracy: 0.3824\n",
      "Epoch 222/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6719 - accuracy: 0.7518 - val_loss: 2.2284 - val_accuracy: 0.3906\n",
      "Epoch 223/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6621 - accuracy: 0.7570 - val_loss: 2.2313 - val_accuracy: 0.3860\n",
      "Epoch 224/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.6608 - accuracy: 0.7570 - val_loss: 2.2792 - val_accuracy: 0.3542\n",
      "Epoch 225/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 0.6645 - accuracy: 0.7557 - val_loss: 2.2514 - val_accuracy: 0.3751\n",
      "Epoch 226/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.6600 - accuracy: 0.7553 - val_loss: 2.2570 - val_accuracy: 0.3833\n",
      "Epoch 227/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.6536 - accuracy: 0.7601 - val_loss: 2.2711 - val_accuracy: 0.3896\n",
      "Epoch 228/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6533 - accuracy: 0.7604 - val_loss: 2.2829 - val_accuracy: 0.3615\n",
      "Epoch 229/500\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.6555 - accuracy: 0.7605 - val_loss: 2.3372 - val_accuracy: 0.3778\n",
      "Epoch 230/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6456 - accuracy: 0.7623 - val_loss: 2.3125 - val_accuracy: 0.3633\n",
      "Epoch 231/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6521 - accuracy: 0.7607 - val_loss: 2.3175 - val_accuracy: 0.3778\n",
      "Epoch 232/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6438 - accuracy: 0.7618 - val_loss: 2.2934 - val_accuracy: 0.3742\n",
      "Epoch 233/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.6417 - accuracy: 0.7659 - val_loss: 2.3512 - val_accuracy: 0.3579\n",
      "Epoch 234/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.6483 - accuracy: 0.7654 - val_loss: 2.3409 - val_accuracy: 0.3778\n",
      "Epoch 235/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.6404 - accuracy: 0.7638 - val_loss: 2.3080 - val_accuracy: 0.3669\n",
      "Epoch 236/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.6336 - accuracy: 0.7688 - val_loss: 2.3187 - val_accuracy: 0.3715\n",
      "Epoch 237/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6410 - accuracy: 0.7598 - val_loss: 2.3223 - val_accuracy: 0.3733\n",
      "Epoch 238/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.6320 - accuracy: 0.7672 - val_loss: 2.3448 - val_accuracy: 0.3606\n",
      "Epoch 239/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6290 - accuracy: 0.7677 - val_loss: 2.3291 - val_accuracy: 0.3706\n",
      "Epoch 240/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6282 - accuracy: 0.7676 - val_loss: 2.3457 - val_accuracy: 0.3760\n",
      "Epoch 241/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6275 - accuracy: 0.7680 - val_loss: 2.4282 - val_accuracy: 0.3678\n",
      "Epoch 242/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6270 - accuracy: 0.7733 - val_loss: 2.3664 - val_accuracy: 0.3697\n",
      "Epoch 243/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6213 - accuracy: 0.7738 - val_loss: 2.4677 - val_accuracy: 0.3560\n",
      "Epoch 244/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6210 - accuracy: 0.7727 - val_loss: 2.3698 - val_accuracy: 0.3688\n",
      "Epoch 245/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.6167 - accuracy: 0.7707 - val_loss: 2.4923 - val_accuracy: 0.3569\n",
      "Epoch 246/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6224 - accuracy: 0.7762 - val_loss: 2.3773 - val_accuracy: 0.3697\n",
      "Epoch 247/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6148 - accuracy: 0.7759 - val_loss: 2.4158 - val_accuracy: 0.3824\n",
      "Epoch 248/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.6125 - accuracy: 0.7781 - val_loss: 2.4323 - val_accuracy: 0.3742\n",
      "Epoch 249/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.6144 - accuracy: 0.7770 - val_loss: 2.5077 - val_accuracy: 0.3569\n",
      "Epoch 250/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6104 - accuracy: 0.7788 - val_loss: 2.4148 - val_accuracy: 0.3769\n",
      "Epoch 251/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.6035 - accuracy: 0.7866 - val_loss: 2.4325 - val_accuracy: 0.3751\n",
      "Epoch 252/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6084 - accuracy: 0.7766 - val_loss: 2.4753 - val_accuracy: 0.3533\n",
      "Epoch 253/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6062 - accuracy: 0.7796 - val_loss: 2.4538 - val_accuracy: 0.3778\n",
      "Epoch 254/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.6002 - accuracy: 0.7870 - val_loss: 2.4468 - val_accuracy: 0.3569\n",
      "Epoch 255/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.6024 - accuracy: 0.7817 - val_loss: 2.5183 - val_accuracy: 0.3688\n",
      "Epoch 256/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5960 - accuracy: 0.7842 - val_loss: 2.4544 - val_accuracy: 0.3733\n",
      "Epoch 257/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5948 - accuracy: 0.7880 - val_loss: 2.5037 - val_accuracy: 0.3760\n",
      "Epoch 258/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5964 - accuracy: 0.7844 - val_loss: 2.5103 - val_accuracy: 0.3751\n",
      "Epoch 259/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5898 - accuracy: 0.7872 - val_loss: 2.5415 - val_accuracy: 0.3688\n",
      "Epoch 260/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5910 - accuracy: 0.7865 - val_loss: 2.4933 - val_accuracy: 0.3733\n",
      "Epoch 261/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5872 - accuracy: 0.7879 - val_loss: 2.5473 - val_accuracy: 0.3660\n",
      "Epoch 262/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5940 - accuracy: 0.7882 - val_loss: 2.4870 - val_accuracy: 0.3769\n",
      "Epoch 263/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5802 - accuracy: 0.7905 - val_loss: 2.5348 - val_accuracy: 0.3706\n",
      "Epoch 264/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5813 - accuracy: 0.7924 - val_loss: 2.5414 - val_accuracy: 0.3806\n",
      "Epoch 265/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5844 - accuracy: 0.7883 - val_loss: 2.5645 - val_accuracy: 0.3551\n",
      "Epoch 266/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5748 - accuracy: 0.7962 - val_loss: 2.5299 - val_accuracy: 0.3724\n",
      "Epoch 267/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.5745 - accuracy: 0.7930 - val_loss: 2.5512 - val_accuracy: 0.3569\n",
      "Epoch 268/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5760 - accuracy: 0.7934 - val_loss: 2.6142 - val_accuracy: 0.3588\n",
      "Epoch 269/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5686 - accuracy: 0.7968 - val_loss: 2.5489 - val_accuracy: 0.3597\n",
      "Epoch 270/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.5729 - accuracy: 0.8007 - val_loss: 2.5624 - val_accuracy: 0.3815\n",
      "Epoch 271/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5650 - accuracy: 0.8010 - val_loss: 2.5572 - val_accuracy: 0.3633\n",
      "Epoch 272/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5694 - accuracy: 0.7963 - val_loss: 2.5557 - val_accuracy: 0.3715\n",
      "Epoch 273/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5649 - accuracy: 0.8002 - val_loss: 2.5794 - val_accuracy: 0.3660\n",
      "Epoch 274/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.5601 - accuracy: 0.8026 - val_loss: 2.6804 - val_accuracy: 0.3460\n",
      "Epoch 275/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.5611 - accuracy: 0.7986 - val_loss: 2.7099 - val_accuracy: 0.3615\n",
      "Epoch 276/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.5542 - accuracy: 0.8018 - val_loss: 2.6657 - val_accuracy: 0.3633\n",
      "Epoch 277/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5597 - accuracy: 0.8020 - val_loss: 2.5970 - val_accuracy: 0.3806\n",
      "Epoch 278/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5509 - accuracy: 0.8064 - val_loss: 2.6596 - val_accuracy: 0.3688\n",
      "Epoch 279/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5543 - accuracy: 0.8038 - val_loss: 2.6227 - val_accuracy: 0.3633\n",
      "Epoch 280/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5523 - accuracy: 0.8008 - val_loss: 2.7164 - val_accuracy: 0.3351\n",
      "Epoch 281/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5456 - accuracy: 0.8090 - val_loss: 2.7006 - val_accuracy: 0.3769\n",
      "Epoch 282/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5521 - accuracy: 0.8021 - val_loss: 2.6451 - val_accuracy: 0.3842\n",
      "Epoch 283/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5465 - accuracy: 0.8040 - val_loss: 2.6623 - val_accuracy: 0.3606\n",
      "Epoch 284/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5454 - accuracy: 0.8110 - val_loss: 2.6536 - val_accuracy: 0.3606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5396 - accuracy: 0.8133 - val_loss: 2.6975 - val_accuracy: 0.3678\n",
      "Epoch 286/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5448 - accuracy: 0.8074 - val_loss: 2.6466 - val_accuracy: 0.3715\n",
      "Epoch 287/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5339 - accuracy: 0.8130 - val_loss: 2.8259 - val_accuracy: 0.3597\n",
      "Epoch 288/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5367 - accuracy: 0.8118 - val_loss: 2.7021 - val_accuracy: 0.3860\n",
      "Epoch 289/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5353 - accuracy: 0.8119 - val_loss: 2.8551 - val_accuracy: 0.3406\n",
      "Epoch 290/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5267 - accuracy: 0.8119 - val_loss: 2.7068 - val_accuracy: 0.3778\n",
      "Epoch 291/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5247 - accuracy: 0.8200 - val_loss: 2.7035 - val_accuracy: 0.3660\n",
      "Epoch 292/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5278 - accuracy: 0.8157 - val_loss: 2.7379 - val_accuracy: 0.3460\n",
      "Epoch 293/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5174 - accuracy: 0.8185 - val_loss: 2.7290 - val_accuracy: 0.3642\n",
      "Epoch 294/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5246 - accuracy: 0.8164 - val_loss: 2.7543 - val_accuracy: 0.3660\n",
      "Epoch 295/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5185 - accuracy: 0.8193 - val_loss: 2.7337 - val_accuracy: 0.3624\n",
      "Epoch 296/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5193 - accuracy: 0.8145 - val_loss: 2.7599 - val_accuracy: 0.3588\n",
      "Epoch 297/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5186 - accuracy: 0.8205 - val_loss: 2.7982 - val_accuracy: 0.3706\n",
      "Epoch 298/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5113 - accuracy: 0.8258 - val_loss: 2.7422 - val_accuracy: 0.3642\n",
      "Epoch 299/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5138 - accuracy: 0.8220 - val_loss: 2.7797 - val_accuracy: 0.3706\n",
      "Epoch 300/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5068 - accuracy: 0.8235 - val_loss: 2.8073 - val_accuracy: 0.3787\n",
      "Epoch 301/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5146 - accuracy: 0.8214 - val_loss: 2.7664 - val_accuracy: 0.3669\n",
      "Epoch 302/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5085 - accuracy: 0.8255 - val_loss: 2.7780 - val_accuracy: 0.3588\n",
      "Epoch 303/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5080 - accuracy: 0.8236 - val_loss: 2.7921 - val_accuracy: 0.3479\n",
      "Epoch 304/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5005 - accuracy: 0.8301 - val_loss: 2.8382 - val_accuracy: 0.3515\n",
      "Epoch 305/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5027 - accuracy: 0.8279 - val_loss: 2.9683 - val_accuracy: 0.3279\n",
      "Epoch 306/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5045 - accuracy: 0.8265 - val_loss: 2.8348 - val_accuracy: 0.3697\n",
      "Epoch 307/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4932 - accuracy: 0.8289 - val_loss: 2.8735 - val_accuracy: 0.3678\n",
      "Epoch 308/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.5001 - accuracy: 0.8249 - val_loss: 2.8397 - val_accuracy: 0.3442\n",
      "Epoch 309/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4914 - accuracy: 0.8302 - val_loss: 2.9845 - val_accuracy: 0.3479\n",
      "Epoch 310/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4937 - accuracy: 0.8249 - val_loss: 2.8417 - val_accuracy: 0.3706\n",
      "Epoch 311/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4870 - accuracy: 0.8317 - val_loss: 2.8436 - val_accuracy: 0.3588\n",
      "Epoch 312/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4861 - accuracy: 0.8306 - val_loss: 2.8709 - val_accuracy: 0.3724\n",
      "Epoch 313/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4821 - accuracy: 0.8306 - val_loss: 2.8685 - val_accuracy: 0.3733\n",
      "Epoch 314/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4803 - accuracy: 0.8336 - val_loss: 2.9247 - val_accuracy: 0.3724\n",
      "Epoch 315/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4746 - accuracy: 0.8364 - val_loss: 2.9313 - val_accuracy: 0.3479\n",
      "Epoch 316/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4754 - accuracy: 0.8371 - val_loss: 2.8736 - val_accuracy: 0.3651\n",
      "Epoch 317/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4753 - accuracy: 0.8390 - val_loss: 3.0078 - val_accuracy: 0.3361\n",
      "Epoch 318/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4789 - accuracy: 0.8368 - val_loss: 2.9176 - val_accuracy: 0.3479\n",
      "Epoch 319/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4720 - accuracy: 0.8381 - val_loss: 2.9861 - val_accuracy: 0.3551\n",
      "Epoch 320/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4713 - accuracy: 0.8400 - val_loss: 2.9514 - val_accuracy: 0.3506\n",
      "Epoch 321/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4691 - accuracy: 0.8400 - val_loss: 2.9377 - val_accuracy: 0.3515\n",
      "Epoch 322/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4657 - accuracy: 0.8393 - val_loss: 2.9116 - val_accuracy: 0.3688\n",
      "Epoch 323/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4659 - accuracy: 0.8400 - val_loss: 2.9013 - val_accuracy: 0.3760\n",
      "Epoch 324/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4594 - accuracy: 0.8447 - val_loss: 2.9934 - val_accuracy: 0.3515\n",
      "Epoch 325/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4557 - accuracy: 0.8450 - val_loss: 3.0215 - val_accuracy: 0.3560\n",
      "Epoch 326/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4564 - accuracy: 0.8441 - val_loss: 3.0091 - val_accuracy: 0.3406\n",
      "Epoch 327/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4536 - accuracy: 0.8442 - val_loss: 3.0202 - val_accuracy: 0.3351\n",
      "Epoch 328/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4539 - accuracy: 0.8436 - val_loss: 2.9844 - val_accuracy: 0.3488\n",
      "Epoch 329/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4464 - accuracy: 0.8463 - val_loss: 3.0467 - val_accuracy: 0.3460\n",
      "Epoch 330/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4522 - accuracy: 0.8464 - val_loss: 3.0643 - val_accuracy: 0.3678\n",
      "Epoch 331/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4470 - accuracy: 0.8485 - val_loss: 3.0273 - val_accuracy: 0.3624\n",
      "Epoch 332/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4459 - accuracy: 0.8453 - val_loss: 3.0299 - val_accuracy: 0.3533\n",
      "Epoch 333/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4371 - accuracy: 0.8562 - val_loss: 3.0708 - val_accuracy: 0.3315\n",
      "Epoch 334/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4465 - accuracy: 0.8455 - val_loss: 3.0158 - val_accuracy: 0.3651\n",
      "Epoch 335/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4393 - accuracy: 0.8538 - val_loss: 3.0872 - val_accuracy: 0.3488\n",
      "Epoch 336/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4366 - accuracy: 0.8535 - val_loss: 3.1083 - val_accuracy: 0.3524\n",
      "Epoch 337/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4333 - accuracy: 0.8545 - val_loss: 3.0438 - val_accuracy: 0.3533\n",
      "Epoch 338/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4345 - accuracy: 0.8516 - val_loss: 3.0571 - val_accuracy: 0.3624\n",
      "Epoch 339/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4309 - accuracy: 0.8517 - val_loss: 3.1068 - val_accuracy: 0.3451\n",
      "Epoch 340/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4251 - accuracy: 0.8579 - val_loss: 3.1325 - val_accuracy: 0.3460\n",
      "Epoch 341/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4304 - accuracy: 0.8558 - val_loss: 3.0585 - val_accuracy: 0.3533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.4204 - accuracy: 0.8563 - val_loss: 3.0876 - val_accuracy: 0.3506\n",
      "Epoch 343/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.4247 - accuracy: 0.8578 - val_loss: 3.0764 - val_accuracy: 0.3651\n",
      "Epoch 344/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.4155 - accuracy: 0.8581 - val_loss: 3.1099 - val_accuracy: 0.3524\n",
      "Epoch 345/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.4138 - accuracy: 0.8620 - val_loss: 3.1008 - val_accuracy: 0.3533\n",
      "Epoch 346/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.4135 - accuracy: 0.8606 - val_loss: 3.1889 - val_accuracy: 0.3370\n",
      "Epoch 347/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.4097 - accuracy: 0.8610 - val_loss: 3.1723 - val_accuracy: 0.3379\n",
      "Epoch 348/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.4147 - accuracy: 0.8574 - val_loss: 3.0920 - val_accuracy: 0.3633\n",
      "Epoch 349/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.4133 - accuracy: 0.8605 - val_loss: 3.1371 - val_accuracy: 0.3588\n",
      "Epoch 350/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.4077 - accuracy: 0.8661 - val_loss: 3.1680 - val_accuracy: 0.3506\n",
      "Epoch 351/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3992 - accuracy: 0.8612 - val_loss: 3.2769 - val_accuracy: 0.3651\n",
      "Epoch 352/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.4037 - accuracy: 0.8646 - val_loss: 3.1378 - val_accuracy: 0.3597\n",
      "Epoch 353/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.4042 - accuracy: 0.8639 - val_loss: 3.1605 - val_accuracy: 0.3606\n",
      "Epoch 354/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3981 - accuracy: 0.8649 - val_loss: 3.1725 - val_accuracy: 0.3442\n",
      "Epoch 355/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.3936 - accuracy: 0.8653 - val_loss: 3.2356 - val_accuracy: 0.3488\n",
      "Epoch 356/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3911 - accuracy: 0.8667 - val_loss: 3.2505 - val_accuracy: 0.3569\n",
      "Epoch 357/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.3951 - accuracy: 0.8693 - val_loss: 3.2494 - val_accuracy: 0.3624\n",
      "Epoch 358/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.3916 - accuracy: 0.8660 - val_loss: 3.2455 - val_accuracy: 0.3424\n",
      "Epoch 359/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3905 - accuracy: 0.8682 - val_loss: 3.2524 - val_accuracy: 0.3433\n",
      "Epoch 360/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.3815 - accuracy: 0.8724 - val_loss: 3.2037 - val_accuracy: 0.3588\n",
      "Epoch 361/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3759 - accuracy: 0.8746 - val_loss: 3.2321 - val_accuracy: 0.3569\n",
      "Epoch 362/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3824 - accuracy: 0.8713 - val_loss: 3.3052 - val_accuracy: 0.3370\n",
      "Epoch 363/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3767 - accuracy: 0.8714 - val_loss: 3.2205 - val_accuracy: 0.3524\n",
      "Epoch 364/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.3735 - accuracy: 0.8750 - val_loss: 3.2331 - val_accuracy: 0.3624\n",
      "Epoch 365/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3723 - accuracy: 0.8761 - val_loss: 3.2899 - val_accuracy: 0.3560\n",
      "Epoch 366/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.3720 - accuracy: 0.8738 - val_loss: 3.2594 - val_accuracy: 0.3588\n",
      "Epoch 367/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3743 - accuracy: 0.8745 - val_loss: 3.2626 - val_accuracy: 0.3506\n",
      "Epoch 368/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.3713 - accuracy: 0.8761 - val_loss: 3.2825 - val_accuracy: 0.3633\n",
      "Epoch 369/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3702 - accuracy: 0.8770 - val_loss: 3.3108 - val_accuracy: 0.3533\n",
      "Epoch 370/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.3695 - accuracy: 0.8766 - val_loss: 3.3775 - val_accuracy: 0.3279\n",
      "Epoch 371/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3592 - accuracy: 0.8778 - val_loss: 3.3037 - val_accuracy: 0.3597\n",
      "Epoch 372/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3620 - accuracy: 0.8737 - val_loss: 3.2904 - val_accuracy: 0.3606\n",
      "Epoch 373/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3574 - accuracy: 0.8809 - val_loss: 3.3473 - val_accuracy: 0.3633\n",
      "Epoch 374/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3569 - accuracy: 0.8787 - val_loss: 3.3291 - val_accuracy: 0.3470\n",
      "Epoch 375/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.3544 - accuracy: 0.8789 - val_loss: 3.3310 - val_accuracy: 0.3533\n",
      "Epoch 376/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.3538 - accuracy: 0.8846 - val_loss: 3.3405 - val_accuracy: 0.3524\n",
      "Epoch 377/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.3532 - accuracy: 0.8796 - val_loss: 3.4119 - val_accuracy: 0.3470\n",
      "Epoch 378/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3490 - accuracy: 0.8830 - val_loss: 3.4374 - val_accuracy: 0.3515\n",
      "Epoch 379/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.3479 - accuracy: 0.8837 - val_loss: 3.3682 - val_accuracy: 0.3579\n",
      "Epoch 380/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3448 - accuracy: 0.8849 - val_loss: 3.4058 - val_accuracy: 0.3579\n",
      "Epoch 381/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.3440 - accuracy: 0.8849 - val_loss: 3.3791 - val_accuracy: 0.3533\n",
      "Epoch 382/500\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 0.3384 - accuracy: 0.8879 - val_loss: 3.5394 - val_accuracy: 0.3370\n",
      "Epoch 383/500\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 0.3435 - accuracy: 0.8857 - val_loss: 3.3794 - val_accuracy: 0.3533\n",
      "Epoch 384/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.3370 - accuracy: 0.8894 - val_loss: 3.4127 - val_accuracy: 0.3579\n",
      "Epoch 385/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.3312 - accuracy: 0.8849 - val_loss: 3.4021 - val_accuracy: 0.3460\n",
      "Epoch 386/500\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.3319 - accuracy: 0.8903 - val_loss: 3.4614 - val_accuracy: 0.3406\n",
      "Epoch 387/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.3289 - accuracy: 0.8920 - val_loss: 3.4596 - val_accuracy: 0.3533\n",
      "Epoch 388/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.3300 - accuracy: 0.8919 - val_loss: 3.4896 - val_accuracy: 0.3588\n",
      "Epoch 389/500\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.3281 - accuracy: 0.8917 - val_loss: 3.4723 - val_accuracy: 0.3560\n",
      "Epoch 390/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.3238 - accuracy: 0.8917 - val_loss: 3.5673 - val_accuracy: 0.3342\n",
      "Epoch 391/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3305 - accuracy: 0.8910 - val_loss: 3.5172 - val_accuracy: 0.3488\n",
      "Epoch 392/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3202 - accuracy: 0.8920 - val_loss: 3.5408 - val_accuracy: 0.3488\n",
      "Epoch 393/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3171 - accuracy: 0.8969 - val_loss: 3.5600 - val_accuracy: 0.3678\n",
      "Epoch 394/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3236 - accuracy: 0.8916 - val_loss: 3.5790 - val_accuracy: 0.3542\n",
      "Epoch 395/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3132 - accuracy: 0.8967 - val_loss: 3.5757 - val_accuracy: 0.3442\n",
      "Epoch 396/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3197 - accuracy: 0.8930 - val_loss: 3.5339 - val_accuracy: 0.3488\n",
      "Epoch 397/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3106 - accuracy: 0.8971 - val_loss: 3.5567 - val_accuracy: 0.3506\n",
      "Epoch 398/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3074 - accuracy: 0.8985 - val_loss: 3.5919 - val_accuracy: 0.3424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.3113 - accuracy: 0.8944 - val_loss: 3.5743 - val_accuracy: 0.3515\n",
      "Epoch 400/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.3120 - accuracy: 0.8930 - val_loss: 3.6303 - val_accuracy: 0.3433\n",
      "Epoch 401/500\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 0.3009 - accuracy: 0.9012 - val_loss: 3.6012 - val_accuracy: 0.3415\n",
      "Epoch 402/500\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.3039 - accuracy: 0.8997 - val_loss: 3.6263 - val_accuracy: 0.3515\n",
      "Epoch 403/500\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 0.3028 - accuracy: 0.9000 - val_loss: 3.6475 - val_accuracy: 0.3379\n",
      "Epoch 404/500\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.2997 - accuracy: 0.9026 - val_loss: 3.5877 - val_accuracy: 0.3588\n",
      "Epoch 405/500\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.2961 - accuracy: 0.9029 - val_loss: 3.7791 - val_accuracy: 0.3324\n",
      "Epoch 406/500\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 0.2979 - accuracy: 0.8995 - val_loss: 3.6128 - val_accuracy: 0.3560\n",
      "Epoch 407/500\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.2874 - accuracy: 0.9068 - val_loss: 3.6849 - val_accuracy: 0.3488\n",
      "Epoch 408/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.2958 - accuracy: 0.9034 - val_loss: 3.6648 - val_accuracy: 0.3551\n",
      "Epoch 409/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2889 - accuracy: 0.9037 - val_loss: 3.6693 - val_accuracy: 0.3588\n",
      "Epoch 410/500\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 0.2900 - accuracy: 0.9041 - val_loss: 3.6852 - val_accuracy: 0.3460\n",
      "Epoch 411/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.2861 - accuracy: 0.9077 - val_loss: 3.7088 - val_accuracy: 0.3470\n",
      "Epoch 412/500\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 0.2882 - accuracy: 0.9073 - val_loss: 3.6965 - val_accuracy: 0.3579\n",
      "Epoch 413/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2791 - accuracy: 0.9071 - val_loss: 3.7230 - val_accuracy: 0.3451\n",
      "Epoch 414/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.2873 - accuracy: 0.9045 - val_loss: 3.7070 - val_accuracy: 0.3551\n",
      "Epoch 415/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.2838 - accuracy: 0.9060 - val_loss: 3.7385 - val_accuracy: 0.3442\n",
      "Epoch 416/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2772 - accuracy: 0.9079 - val_loss: 3.8846 - val_accuracy: 0.3370\n",
      "Epoch 417/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2760 - accuracy: 0.9107 - val_loss: 3.7517 - val_accuracy: 0.3524\n",
      "Epoch 418/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2804 - accuracy: 0.9072 - val_loss: 3.7524 - val_accuracy: 0.3533\n",
      "Epoch 419/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2731 - accuracy: 0.9081 - val_loss: 3.8106 - val_accuracy: 0.3542\n",
      "Epoch 420/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2709 - accuracy: 0.9114 - val_loss: 3.8181 - val_accuracy: 0.3551\n",
      "Epoch 421/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.2734 - accuracy: 0.9108 - val_loss: 3.7897 - val_accuracy: 0.3424\n",
      "Epoch 422/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2705 - accuracy: 0.9116 - val_loss: 3.8032 - val_accuracy: 0.3470\n",
      "Epoch 423/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2694 - accuracy: 0.9088 - val_loss: 3.8426 - val_accuracy: 0.3361\n",
      "Epoch 424/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2655 - accuracy: 0.9089 - val_loss: 3.8883 - val_accuracy: 0.3515\n",
      "Epoch 425/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.2658 - accuracy: 0.9100 - val_loss: 3.9387 - val_accuracy: 0.3324\n",
      "Epoch 426/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2644 - accuracy: 0.9143 - val_loss: 3.8574 - val_accuracy: 0.3524\n",
      "Epoch 427/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2604 - accuracy: 0.9120 - val_loss: 3.9145 - val_accuracy: 0.3460\n",
      "Epoch 428/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2585 - accuracy: 0.9141 - val_loss: 3.8478 - val_accuracy: 0.3433\n",
      "Epoch 429/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2601 - accuracy: 0.9139 - val_loss: 3.8968 - val_accuracy: 0.3497\n",
      "Epoch 430/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2615 - accuracy: 0.9136 - val_loss: 3.9806 - val_accuracy: 0.3424\n",
      "Epoch 431/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2550 - accuracy: 0.9153 - val_loss: 3.9112 - val_accuracy: 0.3542\n",
      "Epoch 432/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 0.2545 - accuracy: 0.9168 - val_loss: 3.9080 - val_accuracy: 0.3515\n",
      "Epoch 433/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2545 - accuracy: 0.9153 - val_loss: 4.0052 - val_accuracy: 0.3579\n",
      "Epoch 434/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.2505 - accuracy: 0.9176 - val_loss: 3.9457 - val_accuracy: 0.3515\n",
      "Epoch 435/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2547 - accuracy: 0.9165 - val_loss: 3.9490 - val_accuracy: 0.3597\n",
      "Epoch 436/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2464 - accuracy: 0.9185 - val_loss: 4.0017 - val_accuracy: 0.3515\n",
      "Epoch 437/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2484 - accuracy: 0.9183 - val_loss: 3.9945 - val_accuracy: 0.3406\n",
      "Epoch 438/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.2455 - accuracy: 0.9170 - val_loss: 3.9795 - val_accuracy: 0.3406\n",
      "Epoch 439/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2470 - accuracy: 0.9188 - val_loss: 4.1001 - val_accuracy: 0.3488\n",
      "Epoch 440/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2413 - accuracy: 0.9206 - val_loss: 4.0289 - val_accuracy: 0.3551\n",
      "Epoch 441/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2410 - accuracy: 0.9189 - val_loss: 4.0436 - val_accuracy: 0.3460\n",
      "Epoch 442/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2385 - accuracy: 0.9215 - val_loss: 4.0212 - val_accuracy: 0.3406\n",
      "Epoch 443/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2392 - accuracy: 0.9180 - val_loss: 4.1550 - val_accuracy: 0.3433\n",
      "Epoch 444/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2353 - accuracy: 0.9208 - val_loss: 4.1222 - val_accuracy: 0.3542\n",
      "Epoch 445/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2399 - accuracy: 0.9184 - val_loss: 4.0442 - val_accuracy: 0.3506\n",
      "Epoch 446/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2322 - accuracy: 0.9251 - val_loss: 4.0707 - val_accuracy: 0.3470\n",
      "Epoch 447/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2348 - accuracy: 0.9245 - val_loss: 4.1355 - val_accuracy: 0.3488\n",
      "Epoch 448/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2298 - accuracy: 0.9246 - val_loss: 4.1847 - val_accuracy: 0.3560\n",
      "Epoch 449/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.2242 - accuracy: 0.9249 - val_loss: 4.2479 - val_accuracy: 0.3470\n",
      "Epoch 450/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2285 - accuracy: 0.9261 - val_loss: 4.1466 - val_accuracy: 0.3542\n",
      "Epoch 451/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.2275 - accuracy: 0.9246 - val_loss: 4.3270 - val_accuracy: 0.3342\n",
      "Epoch 452/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2217 - accuracy: 0.9252 - val_loss: 4.2372 - val_accuracy: 0.3397\n",
      "Epoch 453/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2196 - accuracy: 0.9267 - val_loss: 4.2406 - val_accuracy: 0.3451\n",
      "Epoch 454/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.2245 - accuracy: 0.9257 - val_loss: 4.1346 - val_accuracy: 0.3460\n",
      "Epoch 455/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2236 - accuracy: 0.9291 - val_loss: 4.2139 - val_accuracy: 0.3606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2189 - accuracy: 0.9263 - val_loss: 4.1986 - val_accuracy: 0.3397\n",
      "Epoch 457/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2224 - accuracy: 0.9267 - val_loss: 4.1830 - val_accuracy: 0.3424\n",
      "Epoch 458/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.2183 - accuracy: 0.9278 - val_loss: 4.2235 - val_accuracy: 0.3597\n",
      "Epoch 459/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2187 - accuracy: 0.9251 - val_loss: 4.2495 - val_accuracy: 0.3479\n",
      "Epoch 460/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2125 - accuracy: 0.9297 - val_loss: 4.2676 - val_accuracy: 0.3497\n",
      "Epoch 461/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2123 - accuracy: 0.9288 - val_loss: 4.2987 - val_accuracy: 0.3479\n",
      "Epoch 462/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2139 - accuracy: 0.9274 - val_loss: 4.3684 - val_accuracy: 0.3424\n",
      "Epoch 463/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.2081 - accuracy: 0.9299 - val_loss: 4.3149 - val_accuracy: 0.3442\n",
      "Epoch 464/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2127 - accuracy: 0.9305 - val_loss: 4.3667 - val_accuracy: 0.3424\n",
      "Epoch 465/500\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.2099 - accuracy: 0.9318 - val_loss: 4.3217 - val_accuracy: 0.3388\n",
      "Epoch 466/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2083 - accuracy: 0.9311 - val_loss: 4.3241 - val_accuracy: 0.3479\n",
      "Epoch 467/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 0.2044 - accuracy: 0.9321 - val_loss: 4.4331 - val_accuracy: 0.3324\n",
      "Epoch 468/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.2085 - accuracy: 0.9315 - val_loss: 4.3369 - val_accuracy: 0.3460\n",
      "Epoch 469/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.2036 - accuracy: 0.9322 - val_loss: 4.3466 - val_accuracy: 0.3351\n",
      "Epoch 470/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2054 - accuracy: 0.9319 - val_loss: 4.3675 - val_accuracy: 0.3533\n",
      "Epoch 471/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.2033 - accuracy: 0.9321 - val_loss: 4.3543 - val_accuracy: 0.3415\n",
      "Epoch 472/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.2038 - accuracy: 0.9313 - val_loss: 4.4509 - val_accuracy: 0.3515\n",
      "Epoch 473/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1998 - accuracy: 0.9349 - val_loss: 4.4316 - val_accuracy: 0.3597\n",
      "Epoch 474/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1997 - accuracy: 0.9352 - val_loss: 4.4546 - val_accuracy: 0.3470\n",
      "Epoch 475/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1970 - accuracy: 0.9352 - val_loss: 4.4517 - val_accuracy: 0.3388\n",
      "Epoch 476/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1958 - accuracy: 0.9332 - val_loss: 4.4880 - val_accuracy: 0.3397\n",
      "Epoch 477/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1963 - accuracy: 0.9353 - val_loss: 4.5092 - val_accuracy: 0.3406\n",
      "Epoch 478/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1966 - accuracy: 0.9327 - val_loss: 4.4696 - val_accuracy: 0.3533\n",
      "Epoch 479/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1945 - accuracy: 0.9338 - val_loss: 4.6303 - val_accuracy: 0.3315\n",
      "Epoch 480/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1958 - accuracy: 0.9366 - val_loss: 4.4984 - val_accuracy: 0.3470\n",
      "Epoch 481/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1892 - accuracy: 0.9380 - val_loss: 4.5216 - val_accuracy: 0.3451\n",
      "Epoch 482/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.1891 - accuracy: 0.9373 - val_loss: 4.5500 - val_accuracy: 0.3442\n",
      "Epoch 483/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.1861 - accuracy: 0.9381 - val_loss: 4.5939 - val_accuracy: 0.3479\n",
      "Epoch 484/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.1892 - accuracy: 0.9370 - val_loss: 4.6010 - val_accuracy: 0.3678\n",
      "Epoch 485/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.1842 - accuracy: 0.9405 - val_loss: 4.5965 - val_accuracy: 0.3451\n",
      "Epoch 486/500\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.1901 - accuracy: 0.9362 - val_loss: 4.5698 - val_accuracy: 0.3560\n",
      "Epoch 487/500\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 0.1842 - accuracy: 0.9417 - val_loss: 4.6429 - val_accuracy: 0.3460\n",
      "Epoch 488/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.1824 - accuracy: 0.9390 - val_loss: 4.6344 - val_accuracy: 0.3569\n",
      "Epoch 489/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.1793 - accuracy: 0.9407 - val_loss: 4.6419 - val_accuracy: 0.3442\n",
      "Epoch 490/500\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 0.1826 - accuracy: 0.9404 - val_loss: 4.6815 - val_accuracy: 0.3488\n",
      "Epoch 491/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1780 - accuracy: 0.9409 - val_loss: 4.6538 - val_accuracy: 0.3533\n",
      "Epoch 492/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.1777 - accuracy: 0.9431 - val_loss: 4.7490 - val_accuracy: 0.3388\n",
      "Epoch 493/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 0.1769 - accuracy: 0.9394 - val_loss: 4.7421 - val_accuracy: 0.3397\n",
      "Epoch 494/500\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.1753 - accuracy: 0.9439 - val_loss: 4.7416 - val_accuracy: 0.3406\n",
      "Epoch 495/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.1734 - accuracy: 0.9412 - val_loss: 4.6987 - val_accuracy: 0.3533\n",
      "Epoch 496/500\n",
      "67/67 [==============================] - 1s 20ms/step - loss: 0.1760 - accuracy: 0.9409 - val_loss: 4.7585 - val_accuracy: 0.3506\n",
      "Epoch 497/500\n",
      "67/67 [==============================] - 1s 21ms/step - loss: 0.1758 - accuracy: 0.9450 - val_loss: 4.7689 - val_accuracy: 0.3451\n",
      "Epoch 498/500\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 0.1698 - accuracy: 0.9449 - val_loss: 4.7815 - val_accuracy: 0.3361\n",
      "Epoch 499/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1679 - accuracy: 0.9473 - val_loss: 4.8078 - val_accuracy: 0.3397\n",
      "Epoch 500/500\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.1711 - accuracy: 0.9456 - val_loss: 4.8490 - val_accuracy: 0.3206\n"
     ]
    }
   ],
   "source": [
    "# DEFINE all parameters here for tuning\n",
    "pool_flag = 'mean'\n",
    "embedding_fix = False\n",
    "rate = 2\n",
    "layer_sizes = [128*rate, 80*rate, 20*rate]\n",
    "\n",
    "vocab_dim = 300\n",
    "input_length = 56\n",
    "n_epoch = 500\n",
    "batch_size = 128\n",
    "lr = 0.0001\n",
    "\n",
    "# Training process\n",
    "cpu_count = multiprocessing.cpu_count() # 4\n",
    "\n",
    "#define the early_stopping function\n",
    "#early_stopping = EarlyStopping(monitor=val_loss,patience=10)\n",
    "#define the model\n",
    "model = Sequential()\n",
    "\n",
    "#add the embedding\n",
    "model.add(Embedding(output_dim=vocab_dim,\n",
    "                    input_dim = VOCAB_SIZE + 1,\n",
    "                    mask_zero = True,\n",
    "                    weights = [embedding_weights],\n",
    "                    input_length = input_length,\n",
    "                    trainable = not(embedding_fix)))\n",
    "\n",
    "#add pooling layer\n",
    "model.add(Masking(mask_value = 0.0))\n",
    "if pool_flag == 'mean':\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "else:\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#add layers of MLP\n",
    "for i in layer_sizes:\n",
    "    model.add(Dense(units = i, activation = 'relu'))\n",
    "model.add(Dense(units = 5, activation = 'softmax'))\n",
    "\n",
    "#using cross entropy loss and Adam optimizer\n",
    "rms = keras.optimizers.RMSprop(lr = lr, rho = 0.9, epsilon = None, decay = 0.0)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = rms,metrics = ['accuracy'])\n",
    "#use fit function to do gradient descent, save the accuracy and loss of each epoch in history\n",
    "history = model.fit(train_x, train_y, batch_size = batch_size, epochs = n_epoch, verbose = 1, validation_data = (valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9346\n",
      "Validation set\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 4.8490 - accuracy: 0.3206\n",
      "Test set\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.4255 - accuracy: 0.3552\n"
     ]
    }
   ],
   "source": [
    "print (\"Train set\")\n",
    "score = model.evaluate(train_x, train_y,batch_size = batch_size)\n",
    "print (\"Validation set\")\n",
    "score = model.evaluate(valid_x, valid_y,batch_size = batch_size)\n",
    "print (\"Test set\")\n",
    "score = model.evaluate(test_x, test_y,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2array(sentance):\n",
    "    xs, ys = [], []\n",
    "    for i in range(1):\n",
    "        words = re.compile(\"[a-z|\\]+\", re.I).findall(sentance)\n",
    "        wids = [word2index[word] for word in words]\n",
    "        xs.append(wids)\n",
    "    X = pad_sequences(xs, maxlen = 56)\n",
    "    return X\n",
    "\n",
    "#forward propogation to make the prediction\n",
    "def MLP_predict(string):\n",
    "    print ('loading model......') #load the model\n",
    "    with open('../comp0090/mlp.yml', 'r') as f:\n",
    "        yaml_string = yaml.load(f)\n",
    "    model = model_from_yaml(yaml_string)\n",
    "\n",
    "    print ('loading weights......') #Load the weights\n",
    "    model.load_weights('../comp0090/mlp.h5')\n",
    "    rms = keras.optimizers.RMSprop(lr = 0.0001, rho = 0.9, epsilon = None, decay = 0.0)\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = rms, \n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    data = word2array(string)\n",
    "    data.reshape(1, -1)\n",
    "    \n",
    "    #print data\n",
    "    result = model.predict_classes(data)\n",
    "    print (result) # [[1]]\n",
    "    if result[0] == 0:\n",
    "        print ('Very Negative')\n",
    "    elif result[0] == 1:\n",
    "        print ('Slightly Negative')\n",
    "    elif result[0] == 2:\n",
    "        print ('Neutral')\n",
    "    elif result[0] == 3:\n",
    "        print ('Slightly Positive')\n",
    "    else:\n",
    "        print ('Very Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_predict('The lighthearted tone and smart pacing allow for unwavering entertainment, plenty of natural humor, and Spielbergs knack for sympathizing with antiheroes.')\n",
    "\n",
    "#Score:4/5 https://www.rottentomatoes.com/m/catch_me_if_you_can/reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_predict('The movie is a good time. It not only produces happiness, it is happy.')\n",
    "\n",
    "#Score:5/5 https://www.rottentomatoes.com/m/catch_me_if_you_can/reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_predict('Offers mild fun but never as much as its animated 60s-retro opening credits portend.')\n",
    "\n",
    "#Score:3/5 https://www.rottentomatoes.com/m/catch_me_if_you_can/reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_predict('Its insulting to its source material, its insulting to fans of that source material, and its insulting to its audiences intelligence.')\n",
    "\n",
    "#Score:0.75/5 https://www.rottentomatoes.com/m/pixels/reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_predict('Bad movie Pixels is just the latest pock mark on Adam Sandlers still downtrending career, only noteworthy in its unprecedented slothfulness.')\n",
    "\n",
    "#Score:1/5 https://www.rottentomatoes.com/m/pixels/reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
